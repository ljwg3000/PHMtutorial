{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold = 5\n",
    "\n",
    "# k-fold 데이터\n",
    "for i in range(Fold):\n",
    "    \n",
    "    j = i+1\n",
    "    path1 = './SavedData/Training_Fold%d'%j\n",
    "    path2 = './SavedData/Validation_Fold%d'%j\n",
    "    c1 = 'Training_%d = np.array(pd.read_csv(path1, sep = \",\", header = None))'%j\n",
    "    c2 = 'Validation_%d = np.array(pd.read_csv(path2, sep = \",\", header = None))'%j\n",
    "    exec(c1)\n",
    "    exec(c2)\n",
    "\n",
    "# 학습 및 검증 데이터\n",
    "Training_Label   = np.array(pd.read_csv('./SavedData/Training_Label', sep = \",\", header = None))\n",
    "Validation_Label = np.array(pd.read_csv('./SavedData/Validation_Label', sep = \",\", header = None))\n",
    "\n",
    "# 전체 학습용 데이터\n",
    "Training_TotalData  = np.array(pd.read_csv('./SavedData/Training_TotalData', sep = \",\", header = None))\n",
    "Training_TotalLabel = np.array(pd.read_csv('./SavedData/Training_TotalLabel', sep = \",\", header = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN(Neural Network) hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate  = 0.0001\n",
    "noOfNeuron    = 20\n",
    "iteration     = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN(Neural Network)의 구조(Architecture) 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, Training_1.shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# dropout (keep_prob) rate 0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# Xavier : initializer=tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "# Input Layer\n",
    "W2 = tf.get_variable(\"W2\", shape=[Training_1.shape[1], noOfNeuron],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L2 = tf.nn.relu(tf.matmul(X, W2) + b2)\n",
    "\n",
    "# Hidden Layer 1\n",
    "W3 = tf.get_variable(\"W3\", shape=[noOfNeuron, noOfNeuron],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "# Hidden Layer 2\n",
    "W4 = tf.get_variable(\"W4\", shape=[noOfNeuron, noOfNeuron],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "# Output Layer\n",
    "W5 = tf.get_variable(\"W5\", shape=[noOfNeuron, 2],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([2]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "\n",
    "# define cost/loss &optimizer\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost)\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN(Neural Network) 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = Training_Label\n",
    "\n",
    "for i in range(Fold):\n",
    "    \n",
    "    s1= 'Data = Training_%d'%(i+1)\n",
    "    exec(s1)\n",
    "\n",
    "# train my model\n",
    "# initialize\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(1, iteration+1):\n",
    "    \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = {X : Data, Y: Label})\n",
    "        s2 = 'Validation_Acc_%d = sess.run(accuracy, feed_dict={X : Data, Y: Label})'%(i+1)\n",
    "        exec(s2)\n",
    "\n",
    "Accuracy_sum = 0\n",
    "\n",
    "for j in range(Fold):\n",
    "    \n",
    "    s3 = 'Accuracy_sum += Validation_Acc_%d'%(j+1)\n",
    "    exec(s3)\n",
    "    \n",
    "print('Fold 1: {:.5f} \\nFold 2: {:.5f} \\nFold 3: {:.5f} \\nFold 4: {:.5f} \\nFold 5: {:.5f} \\n\\n * Average accuracy : {:.5f}'\n",
    "      .format(Validation_Acc_1, Validation_Acc_2, Validation_Acc_3, Validation_Acc_4, Validation_Acc_5, Accuracy_sum/Fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 학습 데이터로 NN 학습 및 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Training_TotalData\n",
    "y_data = Training_TotalLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train my model\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(1, iteration+1):\n",
    "    \n",
    "    c, _ = sess.run([cost, optimizer], feed_dict = {X : x_data, Y: y_data})\n",
    "    Acc = sess.run(accuracy, feed_dict={X : x_data, Y: y_data})\n",
    "   \n",
    "    if step % 1000 == 0:\n",
    "            \n",
    "        print('iteration {}'.format(step))    \n",
    "        print('   Validation Acc: {:.5f}'.format(Acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './AI Model/ANN_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model 불러와서 진단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 그래프 초기화 (아무것도 작성안했을 시 실행 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Graph 지울 때 사용\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, Training_1.shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "# dropout (keep_prob) rate 0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# Xavier : initializer=tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "# Input Layer\n",
    "W2 = tf.get_variable(\"W2\", shape=[Training_1.shape[1], noOfNeuron],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L2 = tf.nn.relu(tf.matmul(X, W2) + b2)\n",
    "\n",
    "# Hidden Layer 1\n",
    "W3 = tf.get_variable(\"W3\", shape=[noOfNeuron, noOfNeuron],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "# Hidden Layer 2\n",
    "W4 = tf.get_variable(\"W4\", shape=[noOfNeuron, noOfNeuron],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([noOfNeuron]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "# Output Layer\n",
    "W5 = tf.get_variable(\"W5\", shape=[noOfNeuron, 2],\n",
    "                     initializer=tf.variance_scaling_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([2]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "\n",
    "# define cost/loss &optimizer\n",
    "cost      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(cost)\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기 (그래프에 Variable w, b 불러옴)\n",
    "sess = tf.Session()\n",
    "saver=tf.train.Saver()\n",
    "saver.restore(sess, './AI Model/ANN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 불러온 모델에 넣어 정확도 확인\n",
    "sess.run(accuracy, feed_dict={X : Training_TotalData, Y: Training_TotalLabel})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
